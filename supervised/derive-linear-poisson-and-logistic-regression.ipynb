{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(y|\\mathbf{x}) = \\mathcal{N}(y|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left \\{- \\frac{1}{2} \\frac{(y - \\mu)^2}{\\sigma^2} \\right \\} \\\\\n",
    "$$\n",
    "\n",
    "where $\\sigma^2$ is known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu$ is modeled as $\\mathbf{w}^T \\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the likelihood is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "L \n",
    "&= \\prod_{i=1}^N p(y_i|\\mathbf{x}_i, \\mathbf{w}) \\\\\n",
    "&= \\prod_{i=1}^N \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left \\{- \\frac{1}{2} \\frac{(y_i - \\mathbf{w}^T \\mathbf{x}_i )^2}{\\sigma^2} \\right \\} \\\\\n",
    "&= (2 \\pi \\sigma^2)^{-\\frac{N}{2}} \\prod_{i=1}^N \\exp \\left \\{- \\frac{1}{2} \\frac{(y_i - \\mathbf{w}^T \\mathbf{x}_i )^2}{\\sigma^2} \\right \\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the log-likelihood is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ell \n",
    "&\\propto \\sum_{i=1}^N -\\frac{1}{2} \\frac{(y_i - \\mathbf{w}^T \\mathbf{x}_i)^2 }{\\sigma^2} \\\\\n",
    "&\\propto - \\sum_{i=1}^N (y_i - \\mathbf{w}^T \\mathbf{x}_i)^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, constants are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative of log-likelihood is equivalent to squared loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(y|\\mathbf{x}) = \\text{Poisson}(y|\\lambda) = \\frac{\\lambda^y e^{-\\lambda}}{y!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\lambda$ is also the mean and variance of $p(y|\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $\\lambda$ is always poistive, we model it as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\lambda \n",
    "&= e^{\\mathbf{w}^T \\mathbf{x}} \\\\\n",
    "&= \\mathbb{E}[y|\\mathbf{x}] \\\\\n",
    "& = \\hat{y} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ln \\lambda \n",
    "&= \\mathbf{w}^T \\mathbf{x} \\\\\n",
    "&= \\ln \\mathbb{E}[y|\\mathbf{x}] \\\\\n",
    "&= \\ln \\hat{y} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the logarithmic function is the link function in terms of generalized linear model. (Link function basically maps the valid prediction range into the real number line, which is what $\\mathbf{w}^T \\mathbf{x}$ spans.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "p(y|\\mathbf{x}, \\mathbf{w}) = \\frac{e^{y(\\mathbf{w}^T \\mathbf{x})} e^{- e^{\\mathbf{w}^T \\mathbf{x}}}}{y!}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the likelihood is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "L \n",
    "&= \\prod_{i=1}^N p(y_i|\\mathbf{x}_i, \\mathbf{w}) \\\\\n",
    "&= \\prod_{i=1}^N \\frac{e^{y_i (\\mathbf{w}^T \\mathbf{x}_i)} e^{- e^{\\mathbf{w}^T \\mathbf{x}_i}}}{y_i!}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the log-likelihood is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ell \n",
    "&= \\sum_{i=1}^N y_i \\mathbf{w}^T \\mathbf{x}_i - e^{\\mathbf{w}^T \\mathbf{x}_i} - \\ln (y_i!) \\\\\n",
    "&= \\sum_{i=1}^N y_i \\ln \\hat{y}_i - \\hat{y}_i - \\ln(y_i!)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last term doesn't depend on $w$, we can maximize the first two terms,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ell' &= \\sum_{i=1}^N y_i \\ln \\hat{y}_i - \\hat{y}_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the negative of $\\ell'$, $\\sum_{i=1}^N \\hat{y}_i - y_i \\ln \\hat{y}_i$ can be used as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "p(y|x) = \\text{Bernoulli}(y|q) = q\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we model $q$ as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\hat{y} = q &= \\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}} \\\\\n",
    "\\ln \\frac{\\hat y}{1 - \\hat y} &= \\mathbf{w}^T \\mathbf{x}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the logit function is the link function in terms of generalized linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then the likelihood is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "L \n",
    "&= \\prod_{i=1}^N \\left(\\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}}\\right )^{y_i} \\left(1 - \\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}}\\right )^{1 - y_i} \\\\\n",
    "&= \\prod_{i=1}^N \\left(\\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}}\\right )^{y_i} \\left(\\frac{e^{-\\mathbf{w}^T \\mathbf{x}}}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}}\\right )^{1 - y_i}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-likelihood is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ell \n",
    "&= \\sum_{i=1}^N y_i \\ln \\left(\\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}}\\right ) + (1 - y_i) \\ln \\left(\\frac{e^{-\\mathbf{w}^T \\mathbf{x}}}{1 + e^{-\\mathbf{w}^T \\mathbf{x}}}\\right ) \\\\\n",
    "&= \\sum_{i=1}^N y_i \\ln \\hat{y_i} + (1 - y_i) \\ln(1 - \\hat{y}_i)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative of $\\ell$ can be used as the loss function, aka. log-loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
