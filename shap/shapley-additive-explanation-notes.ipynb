{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Unified Approach to Interpreting Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive feature attribution methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original prediction model $f$ and explanation model $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, $f$ is NOT the real function that generate data, e.g. it's a trained ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $\\mathbf{x}'$ being the simplified features that can be mapped to the original features via\n",
    "\n",
    "\n",
    "$$\\mathbf{x} = h_\\mathbf{x}(\\mathbf{x}')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we try to ensure the property of the explanation model that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g(\\mathbf{z}') \\approx f(h_\\mathbf{x}(\\mathbf{z}'))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whenever $\\mathbf{z}' \\approx \\mathbf{x}'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Additive feature attribution methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g(\\mathbf{z}') = \\phi_0 + \\sum_{i=1}^M \\phi_i z_i'\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where\n",
    "\n",
    "* $g$ is the explanation model\n",
    "* $\\mathbf{z}' \\in \\{0, 1\\}^M$, i.e. a $M$-dimension binary vector, with $M$ being the number of simplified features.\n",
    "* $\\phi_i \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                  |                              | Note                                                               | model to explanation | simplified inputs    |\n",
    "|----------------------------------|------------------------------|--------------------------------------------------------------------|----------------------|----------------------|\n",
    "| LIME                             |                              |                                                                    | blackbox             | interpretable inputs |\n",
    "| DeepLIFT                         |                              |                                                                    | DNN                  |                      |\n",
    "| Layer-wise relevance propagation |                              |                                                                    | DNN                  |                      |\n",
    "| Classic Shapley Value Estimation | Shapley regression values    | needs retrainng models for all subsets of features                 |                      |                      |\n",
    "|                                  | Shapley sampling values      | applying sampling approximation to Shapely regression values       |                      |                      |\n",
    "|                                  | Quantitative Input Influence | Another way of sampling approximation to Shapely regression values |                      |                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple properties uniquely determine additive feature attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Property 1: Local accuracy (aka. local accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(\\mathbf{x}) = g(\\mathbf{x}') = \\phi_0 + \\sum_{i=1}^M \\phi_i x_i'\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which means the explanation model output should match the prediction model output when $\\mathbf{z}' = \\mathbf{x}'$, and hence $\\mathbf{x} = h_\\mathbf{x}(\\mathbf{x}') = h_\\mathbf{x}(\\mathbf{z}')$.\n",
    "\n",
    "Note, \n",
    "\n",
    "* $\\phi_0 = \\mathbb{E}[f(\\mathbf{x})] = f_{\\mathbf{x}}(\\mathbf{0})$, i.e. model output when no features are provided, e.g. average prediction of the labels from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Property 2: Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. when $x_i' = 0$, then $\\phi_i = 0$, i.e. a feature that's not included in the feature vector shouldn't have impact on the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Property 3: Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $y(\\mathbf{z}') = f(h_\\mathbf{x}(\\mathbf{z}'))$, and $\\mathbf{z}_{\\backslash i}$ denote seting $z_i' = 0$ in the simplified binary feature vector. For two models $y_A$ and $y_B$, if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_A(\\mathbf{z}') - y_A(\\mathbf{z}'_{\\backslash i}) \\ge y_B(\\mathbf{z}') - y_B(\\mathbf{z}'_{\\backslash i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which can be expanded to $f_A(h_\\mathbf{x}(\\mathbf{z}')) - f_A(h_\\mathbf{x}(\\mathbf{z}'_{\\backslash i})) \\ge f_B(h_\\mathbf{x}(\\mathbf{z}')) - f_B(h_\\mathbf{x}(\\mathbf{z}'_{\\backslash i}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, then corresponding impact for the $i$th feature in the two models should satisfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi_{A, i} \\ge \\phi_{B, i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the subscript $_A$ and $_B$ identifies which model this $\\phi_i$ belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words, consistency means that for two models, if the exclusion of a feature results in a larger reduction in the predicted value in model A than in model B, then this feature should have a bigger impact in model A than in model B, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Theorem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one possible explanation model that follows the **additive feature attribution methods** can satisfy all three properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi_i(f, \\mathbf{x}) = \\frac{1}{M} \\sum_{\\mathbf{z}' \\subseteq  \\mathbf{x}'} \\binom{M - 1}{|\\mathbf{z}'|}^{-1} \\Big [ f(h_\\mathbf{x}(\\mathbf{z}')) - f(h_\\mathbf{x}(\\mathbf{z}_{\\backslash i}')) \\Big ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note,\n",
    "\n",
    "\n",
    "* when $x_i = 0$, $x_0' = z_0' = 0$, so $\\phi_i(f, \\mathbf{x})$ = 0.\n",
    "* when $x_i \\neq 0$, $x_i' = 1$, $\\mathbf{z}' \\subseteq \\mathbf{x}'$ represents all $\\mathbf{z}'$ vectors where the non-zero entries are a subset of the non-zero entries in $\\mathbf{x}'$ with $z_i' = 1$. This correspond to all subsets of non-zero features $\\mathbf{x}$ always including feature $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on symbols.\n",
    "\n",
    "* $M - 1$ because of exclusion of feature $i$.\n",
    "* $f(h_\\mathbf{x}(\\mathbf{z}'))$ doesn't depend on $i$.\n",
    "* $|\\mathbf{z}'|$ means the number of non-zero elements minus 1 (as $z_i'$ is always equal to 1). The original paper is a bit unclear about this, e.g. if $|\\mathbf{z}'| = M$, $\\binom{M - 1}{M}$ would become undefined.\n",
    "\n",
    "The equation can be interpreted as sum up of all marginal contributions brought by feature $i$ of all possible feature vectors with $i$th feature being $0$ scaled by $\\frac{1}{M}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above equation can also be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi_i(f, \\mathbf{x}) = \\frac{1}{M} \\sum_{R \\in \\mathcal{R}} \\frac{1}{(M - 1)!} \\Big[ f_\\mathbf{x} \\left(P_i^R \\cup i \\right) - f_\\mathbf{x}\\left(P_i^R \\right)\\Big]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi_i(f, \\mathbf{x}) = \\frac{1}{M} \\sum_{S \\in \\mathcal{F}} \\binom{|\\mathcal{F}| - 1}{|S|} ^{-1} \\left(f_\\mathbf{x} (S \\cup i) - f_\\mathbf{x}(S) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where\n",
    "\n",
    "* $\\mathcal{R}$ is the set of all feature ordering (<span style=\"color:red\">TODO: needs to confirm if $\\mathcal{R}$ includes feature $i$ or not</span>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP (SHapley Additive exPlanation) Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kernal SHAP (Lienar LIME + Shapley values)\n",
    "* Deep SHAP (DeepLIFT + Shapley values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI for Trees: From Local Explanations to Global Understanding\n",
    "\n",
    "https://arxiv.org/pdf/1905.04610.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 Estimating $\\mathbb{E}[f(\\mathbf{x})|\\mathbf{x}_S]$\n",
    "\n",
    "Complexity: $O(TLM2^M)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notations\n",
    "\n",
    "* $T$: number of trees\n",
    "* $D$: maximum depth of any tree\n",
    "* $L$: number of leaves\n",
    "* $M$: number of features\n",
    "\n",
    "\n",
    "* $\\mathbf{v}$: vector of nodes, $v_j \\in \\mathcal{R} \\cup \\text{internal}$\n",
    "* $\\mathbf{a}$: vector of indices represent the left child of each internal node\n",
    "* $\\mathbf{b}$: vector of indices represent the right child of each internal node\n",
    "* $\\mathbf{t}$: vector of thresholds for each internal node\n",
    "* $\\mathbf{d}$: vector of indices of features used for splitting in each internal node. $d_j \\in \\text{feature set}$.\n",
    "* $\\mathbf{r}$: vector of covers (i.e. how many data points in the training set fall in the corresponding sub-tree) of each node.\n",
    "\n",
    "All vectors are of length $N$, the number of nodes in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity: $O(TLD^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $m$ is the path of unique features we have split on so far, and contains four attributes:\n",
    "  1. $d$, the feature index, \n",
    "  1. $z$, the fraction of “zero” paths (where this feature is not in the set S) that flow through this branch, \n",
    "  1. $o$, the fraction of “one” paths (where this feature is in the set S) that flow through this branch, and\n",
    "  1. $w$, which is used to hold the proportion of sets of a given cardinality that are present weighted by their Shapley weight\n",
    "  \n",
    "  \n",
    "* $p_z$, fraction of zeros that are going to extend the subsets.\n",
    "* $p_o$, fraction of ones that are going to textend the subsets\n",
    "* $p_i$, index of the feature used to make the last split.\n",
    "\n",
    "hot child: the child followed by the tree when given the input $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
