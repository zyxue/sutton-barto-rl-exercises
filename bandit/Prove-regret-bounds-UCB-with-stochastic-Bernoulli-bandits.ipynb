{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e4a043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67770e5",
   "metadata": {},
   "source": [
    "# Stochastic Bernoulli bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0ece9",
   "metadata": {},
   "source": [
    "YouTue lecture: [Stochastic bandits](https://www.youtube.com/watch?v=Ff23UNTFjGY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e947c3",
   "metadata": {},
   "source": [
    "# Concentration analysis for mean of Bernoulli random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9aa76",
   "metadata": {},
   "source": [
    "Using the Cramér-Chernoff method,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4620e",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbb{P}(\\hat{\\mu} \\ge \\mu + \\epsilon) \n",
    "&= \\mathbb{P} \\left(\\frac{1}{T} \\sum_{t=1}^T X_t \\ge \\mu + \\epsilon \\right) \\\\\n",
    "&= \\mathbb{P} \\left(\\sum_{t=1}^T \\lambda \\left( X_t - \\mu \\right ) \\ge \\lambda T \\epsilon \\right) \\\\\n",
    "&= \\mathbb{P} \\left(e^{ \\sum_{t=1}^T \\lambda \\left( X_t - \\mu \\right )} \\ge e^{\\lambda T \\epsilon } \\right ) \\\\\n",
    "&= \\mathbb{P} \\left( \\prod_{t=1}^T e^{\\lambda \\left( X_t - \\mu \\right )} \\ge e^{\\lambda T \\epsilon} \\right ) \\\\\n",
    "&\\le \\frac{\\mathbb{E}\\left[ \\prod_{t=1}^T e^{\\lambda \\left( X_t - \\mu \\right )} \\right ]}{e^{\\lambda T \\epsilon}} \\\\\n",
    "&= \\frac{\\prod_{t=1}^T \\mathbb{E}\\left[ e^{\\lambda \\left( X_t - \\mu \\right )} \\right ]}{e^{\\lambda T \\epsilon}} \\\\\n",
    "&= \\frac{\\prod_{t=1}^T  \\mu e^{\\lambda (1 - \\mu)} + (1 - \\mu) e^{-\\lambda \\mu}}{e^{\\lambda T \\epsilon}} \\\\\n",
    "&= \\left( \\frac{ \\mu e^{\\lambda (1 - \\mu)} + (1 - \\mu) e^{-\\lambda \\mu}}{e^{\\lambda \\epsilon} } \\right ) ^T \\\\\n",
    "&= \\left( \\mu e^{\\lambda (1 - \\mu - \\epsilon)} + (1 - \\mu) e^{-\\lambda (\\mu + \\epsilon)} \\right ) ^T \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f260967",
   "metadata": {},
   "source": [
    "Note,\n",
    "\n",
    "* In 2nd inequality, $\\lambda$ is a positive random variable we could freely choose.\n",
    "* In 5th inequality, the Markov's inequality is applied\n",
    "* In 6th equality, because $X_1, \\cdots X_t$ are independent, $\\mathbb{E}\\left[ \\prod_{i=1}^T X_i \\right] = \\prod_{i=1}^T \\mathbb{E} \\left[ X_i \\right ]$.\n",
    "* In 7th equality, it expands the expectation given $X_t$ is a Bernoulli random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4902b0",
   "metadata": {},
   "source": [
    "Denote the base in the 9th equality as $Z(\\lambda)$, and the RHS as $B = Z(\\lambda)^T$, minimizing RHS is equivalent to minimizing its log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e96513",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ln B &= T Z(\\lambda)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f4101",
   "metadata": {},
   "source": [
    "Take its derivative wrt. $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b3b0f",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "Z(\\lambda) \n",
    "&= \\mu e^{\\lambda (1 - \\mu - \\epsilon)} + (1 - \\mu) e^{-\\lambda (\\mu + \\epsilon)} \\\\\n",
    "\\frac{\\partial Z(\\lambda)}{\\partial \\lambda} \n",
    "&= \\mu (1 - \\mu - \\epsilon) e^{\\lambda (1 - \\mu - \\epsilon)} - (1 - \\mu)(\\mu + \\epsilon) e^{-\\lambda (\\mu + \\epsilon)} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d825760",
   "metadata": {},
   "source": [
    "Note, we ignored $T$ as it's a constant. By setting $\\frac{\\partial Z(\\lambda)}{\\partial \\lambda} = 0$, assuming $\\epsilon \\in [0, 1 - \\mu]$, otherwise,  we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbc7885",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mu (1 - \\mu - \\epsilon) e^{\\lambda (1 - \\mu - \\epsilon)} - (1 - \\mu)(\\mu + \\epsilon) e^{-\\lambda (\\mu + \\epsilon)} \n",
    "&= 0\\\\\n",
    "\\frac{e^{\\lambda (1 - \\mu - \\epsilon)}}{e^{-\\lambda(\\mu + \\epsilon)}}\n",
    "&=\\frac{(1 - \\mu)(\\mu + \\epsilon)}{\\mu (1 - \\mu - \\epsilon)} \\\\\n",
    "\\lambda \n",
    "&= \\ln \\frac{(1 - \\mu)(\\mu + \\epsilon)}{\\mu (1 - \\mu - \\epsilon)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98ad3a",
   "metadata": {},
   "source": [
    "Take $\\lambda$ into $Z$, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81513b64",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "Z\n",
    "&= \\mu e^{\\lambda (1 - \\mu - \\epsilon)} + (1 - \\mu) e^{\\lambda (0 - \\mu - \\epsilon)} \\\\\n",
    "&= \\mu e^{\\lambda (1 - \\mu - \\epsilon)} + e^{-\\lambda} (1 - \\mu) e^{\\lambda (1 - \\mu - \\epsilon)} \\\\\n",
    "&= \\left[\\mu + e^{-\\lambda}(1 - \\mu) \\right] e^{\\lambda (1 - \\mu - \\epsilon)} \\\\\n",
    "&= \\left[\\mu + \\frac{\\mu(1 - \\mu - \\epsilon)}{\\mu + \\epsilon} \\right] \\left[ \\frac{(1 - \\mu)(\\mu + \\epsilon)}{\\mu (1 - \\mu - \\epsilon)} \\right ]^{1 - \\mu - \\epsilon} \\\\\n",
    "&= \\left[\\mu + \\frac{\\mu(1 - \\mu - \\epsilon)}{\\mu + \\epsilon} \\right] \\left[ \\frac{(1 - \\mu)(\\mu + \\epsilon)}{\\mu (1 - \\mu - \\epsilon)} \\right ]^{1 - \\mu - \\epsilon} \\\\\n",
    "&= \\frac{\\mu}{\\mu + \\epsilon} \\left[ \\frac{(1 - \\mu)(\\mu + \\epsilon)}{\\mu (1 - \\mu - \\epsilon)} \\right ]^{1 - \\mu - \\epsilon} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e8f41",
   "metadata": {},
   "source": [
    "Take log,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b3228d",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ln Z \n",
    "&= \\ln \\frac{\\mu}{\\mu + \\epsilon} + (1 - \\mu - \\epsilon) \\ln \\frac{(1 - \\mu)(\\mu + \\epsilon)}{\\mu (1 - \\mu - \\epsilon)} \\\\\n",
    "&= (1 - \\mu - \\epsilon) \\left( \\ln \\frac{1 - \\mu}{1 - \\mu - \\epsilon} + \\ln \\frac{\\mu + \\epsilon}{\\mu} \\right ) - \\ln \\frac{\\mu + \\epsilon}{\\mu} \\\\\n",
    "&= (1 - \\mu - \\epsilon) \\ln \\frac{1 - \\mu}{1 - \\mu - \\epsilon} - (\\mu + \\epsilon) \\ln \\frac{\\mu + \\epsilon}{\\mu} \\\\\n",
    "&= - \\left[(1 - \\mu - \\epsilon) \\ln \\frac{1 - \\mu - \\epsilon}{1 - \\mu} + (\\mu + \\epsilon) \\ln \\frac{\\mu + \\epsilon}{\\mu} \\right] \\\\\n",
    "&= - D_{KL}(\\mu + \\epsilon, \\mu) \\\\\n",
    "Z &= e^{- D_{KL}(\\mu + \\epsilon, \\mu)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24417d51",
   "metadata": {},
   "source": [
    "Therefore, we obtain the right bound as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c39e3e",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(\\hat{\\mu} \\ge \\mu + \\epsilon) \n",
    "&\\le Z^T =  e^{- T D_{KL}(\\mu + \\epsilon, \\mu)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822122f5",
   "metadata": {},
   "source": [
    "Note, KL divergence is aka. relative entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581481bf",
   "metadata": {},
   "source": [
    "Following the same argument, we can also prove the lower bound,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f8baf",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbb{P}(\\hat{\\mu} \\le \\mu - \\epsilon)\n",
    "&= \\mathbb{P}(- \\hat{\\mu} \\ge - \\mu + \\epsilon) \\\\\n",
    "&= \\mathbb{P}(\\mu - \\hat{\\mu} \\ge \\epsilon) \\\\\n",
    "&= \\mathbb{P}\\left( \\sum_{t = 1}^T (\\mu - X_t) \\ge T \\epsilon \\right ) \\\\\n",
    "&= \\mathbb{P}\\left( e^{\\lambda \\sum_{t = 1}^T (\\mu - X_t)} \\ge e^{\\lambda T \\epsilon} \\right ) \\\\\n",
    "&= \\mathbb{P}\\left( \\prod_{t = 1}^T e^{\\lambda (\\mu - X_t)} \\ge e^{\\lambda T \\epsilon} \\right ) \\\\\n",
    "&\\le \\frac{\\mathbb{E}\\left[ \\prod_{t=1}^T e^{\\lambda (\\mu - X_t)} \\right ]}{e^{\\lambda T \\epsilon}} \\\\\n",
    "&= \\frac{\\prod_{t =1}^T \\mathbb{E}\\left[ e^{\\lambda(\\mu - X_t)} \\right ]}{e^{\\lambda T \\epsilon}} \\\\\n",
    "&= \\frac{\\prod_{t =1}^T \\mu e^{\\lambda(\\mu - 1)} + (1 - \\mu) e^{\\lambda \\mu}}{e^{\\lambda T \\epsilon}} \\\\\n",
    "&= \\left( \\mu e^{\\lambda(\\mu - 1 - \\epsilon)} + (1 - \\mu) e^{\\lambda (\\mu - \\epsilon)} \\right)^T\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05bd1f",
   "metadata": {},
   "source": [
    "Then, let $Z$ be the base in the 9th equality, assuming $\\epsilon \\in [0, \\mu]$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f28fc",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial{Z}}{\\partial \\lambda}\n",
    "= (\\mu - 1 - \\epsilon)\\mu e^{\\lambda (\\mu - 1 - \\epsilon)} + (1 - \\mu)(\\mu - \\epsilon) e^{\\lambda(\\mu - \\epsilon)} \n",
    "&= 0 \\\\\n",
    "\\frac{e^{\\lambda( \\mu - 1 - \\epsilon)}}{e^{\\lambda(\\mu - \\epsilon)}}\n",
    "&= \\frac{(\\mu - 1)(\\mu - \\epsilon)}{\\mu(\\mu - 1 - \\epsilon)} \\\\\n",
    "\\lambda\n",
    "&= \\ln \\frac{\\mu(\\mu - 1 - \\epsilon)}{(\\mu - 1)(\\mu - \\epsilon)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f01064",
   "metadata": {},
   "source": [
    "Replacing $\\lambda$ in the 9th equality,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6d0c4",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "Z\n",
    "&= \\mu e^{\\lambda(\\mu - 1 - \\epsilon)} + (1 - \\mu) e^{\\lambda (\\mu - \\epsilon)} \\\\\n",
    "&= \\left[ \\mu + e^\\lambda (1 - \\mu) \\right ] e^{\\lambda(\\mu - 1 - \\epsilon)} \\\\\n",
    "&= \\left[ \\mu + \\frac{\\mu(\\mu - 1 - \\epsilon)}{(\\mu - 1)(\\mu - \\epsilon)}(1 - \\mu) \\right ] \\left[ \\frac{\\mu(\\mu - 1 - \\epsilon)}{(\\mu - 1)(\\mu - \\epsilon)} \\right ]^{\\mu - 1 - \\epsilon} \\\\\n",
    "&= \\left[ \\mu - \\frac{\\mu(\\mu - 1 - \\epsilon)}{\\mu - \\epsilon} \\right ] \\left[ \\frac{\\mu(\\mu - 1 - \\epsilon)}{(\\mu - 1)(\\mu - \\epsilon)} \\right ]^{\\mu - 1 - \\epsilon} \\\\\n",
    "&= \\frac{\\mu}{\\mu - \\epsilon} \\left[ \\frac{\\mu(\\mu - 1 - \\epsilon)}{(\\mu - 1)(\\mu - \\epsilon)} \\right ]^{\\mu - 1 - \\epsilon} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69900ea0",
   "metadata": {},
   "source": [
    "Take log,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349e795",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ln Z\n",
    "&= \\ln\\frac{\\mu}{\\mu - \\epsilon} + (\\mu - 1 - \\epsilon) \\ln \\frac{\\mu(\\mu - 1 - \\epsilon)}{(\\mu - 1)(\\mu - \\epsilon)} \\\\\n",
    "&= \\ln\\frac{\\mu}{\\mu - \\epsilon} - (1 - \\mu + \\epsilon) \\ln \\frac{\\mu (1 - \\mu + \\epsilon)}{(1 - \\mu)(\\mu - \\epsilon)} \\\\\n",
    "&= \\ln\\frac{\\mu}{\\mu - \\epsilon} - (1 - \\mu + \\epsilon) \\ln \\frac{\\mu}{\\mu - \\epsilon} - (1 - \\mu + \\epsilon) \\ln \\frac{1 - \\mu + \\epsilon}{\\mu - \\epsilon} \\\\\n",
    "&= - (\\mu - \\epsilon) \\frac{\\mu - \\epsilon}{\\mu} - (1 - \\mu + \\epsilon) \\ln \\frac{1 - \\mu + \\epsilon}{\\mu - \\epsilon} \\\\\n",
    "&= - D_{KL}(\\mu - \\epsilon, \\mu)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf43a29",
   "metadata": {},
   "source": [
    "Therefore, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7e19b",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(\\hat{\\mu} \\le \\mu - \\epsilon) \n",
    "&\\le Z^T = e^{- T D_{KL}(\\mu - \\epsilon, \\mu)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41670ca0",
   "metadata": {},
   "source": [
    "Combining both derived tail bounds, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728805e2",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(\\hat{\\mu} \\ge \\mu + \\epsilon) \n",
    "&\\le e^{- T D_{KL}(\\mu + \\epsilon, \\mu)} \\\\\n",
    "\\mathbb{P}(\\hat{\\mu} \\le \\mu - \\epsilon) \n",
    "&\\le e^{- T D_{KL}(\\mu - \\epsilon, \\mu)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb02e0",
   "metadata": {},
   "source": [
    "for $\\epsilon \\in [0, \\min(\\mu, 1 - \\mu)]$. \n",
    "\n",
    "\n",
    "Interestingly, the two bounds aren't the same, which is in contrast to the case for Gaussian r.v. as shown in `Prove-regret-bounds-for-UCB-for-stochastic-Gaussian-bandits-with-variance-1.ipynb`. The reason is because  $X_t - \\mu$ and $\\mu - X_t$ don't have the same distribution (although they both have mean $0$ and variance $\\mu(1 - \\mu)$), so $\\mu - \\hat{\\mu}$ and $\\hat{\\mu} - \\mu$ don't have the same distribution, either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec72187",
   "metadata": {},
   "source": [
    "Using Pinsker's inequality,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43018724",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "D_{KL}(\\mu + \\epsilon, \\mu) &\\ge 2 \\epsilon^2 \\\\\n",
    "D_{KL}(\\mu - \\epsilon, \\mu) &\\ge 2 \\epsilon^2 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0bbe2",
   "metadata": {},
   "source": [
    "So"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1aa758",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(\\hat{\\mu} \\ge \\mu + \\epsilon) \n",
    "&\\le e^{- T D_{KL}(\\mu + \\epsilon, \\mu)} \\le e^{- 2 T \\epsilon^2} \\\\\n",
    "\\mathbb{P}(\\hat{\\mu} \\le \\mu - \\epsilon) \n",
    "&\\le e^{- T D_{KL}(\\mu - \\epsilon, \\mu)} \\le e^{- 2 T \\epsilon^2}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5d0a3",
   "metadata": {},
   "source": [
    "which is the same bound as given by Hoeffding's inequality. Note, the $D_{KL}$ based bound (aka. Chernoff bound in Ch10 of the [book](https://tor-lattimore.com/downloads/book/book.pdf) is tighter than the bound based on Pinsker's inequality/Hoeffding's inequality. But for consistency with the YouTue lecture, we'll use the Hoeffding bound instead.\n",
    "\n",
    "\n",
    "If we set $\\delta = e^{-2 T \\epsilon^2}$, then we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd4d6d",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\epsilon = \\sqrt{\\frac{1}{2T} \\ln \\frac{1}{\\delta}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948236b0",
   "metadata": {},
   "source": [
    "Therefore,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8202323",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(\\left| \\hat{\\mu} - \\mu \\right| \\ge \\epsilon) \n",
    "&\\le 2\\delta \\\\\n",
    "\\mathbb{P}\\left(\\left| \\hat{\\mu} - \\mu \\right| \\ge \\sqrt{\\frac{1}{2T} \\ln \\frac{1}{\\delta}} \\right) \n",
    "&\\le 2\\delta \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2855724",
   "metadata": {},
   "source": [
    "which matches the equation at https://youtu.be/Ff23UNTFjGY?t=3910. Note in a earlier slide at [t=1884](https://youtu.be/Ff23UNTFjGY?t=1884) in the video, it uses $2/\\delta$ instead of $1 / \\delta$ (inconsistently), which can easily be obtained simply just by setting $\\delta / 2 = e^{-2 T \\epsilon^2}$ instead. But we prefer the $1/\\delta$ version, and will it in the following derivations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e4c65",
   "metadata": {},
   "source": [
    "# Regret decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368091c",
   "metadata": {},
   "source": [
    "We'll take the result from `Prove-regret-bounds-for-UCB-for-stochastic-Gaussian-bandits-with-variance-1.ipynb` directly, the regret can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec6a70",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "R_n \n",
    "&= \\sum_{a \\in \\mathcal{A}} \\Delta_a \\mathbb{E}[ T_a(n) ] \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010df078",
   "metadata": {},
   "source": [
    "i.e. the sum of the products of suboptimality gap and the expected number of action plays for all actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba38a7b",
   "metadata": {},
   "source": [
    "Note,\n",
    "\n",
    "* $\\mathcal{A}$ is the set of all actions.\n",
    "* $\\Delta_{a}$ is the suboptimality gap between the best action and action $a$, i.e. $\\Delta_a = \\mu^* - \\mu_a$.\n",
    "* $T_a(n) = \\sum_{t=1}^n  \\mathbb{1}(A_t = a)$ is the number of times out of $n$ rounds action $a$ is played."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e22fda",
   "metadata": {},
   "source": [
    "# Regret bound for UCB algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cacab1",
   "metadata": {},
   "source": [
    "In UCB, we always play the action with the largest upper confidence bound (UCB, i.e. $\\mu_a + \\epsilon$) after initial exploration. Let's denote \n",
    "\n",
    "* $\\hat{\\mu}_a(t)$ as the mean reward estimation for action $a$ after $t$ rounds.\n",
    "* $T_a(t)$ as the number of times action $a$ is played after $t$ rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967d838",
   "metadata": {},
   "source": [
    "**Note**, $t$ is the number of rounds regardless of which action is played, while $T$ is the number of rounds specific to when a particular action $a$ is played, so the two do not correspond to each other. (Maybe a bad choice for the symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070b54d",
   "metadata": {},
   "source": [
    "We also define the good event $E$ as when the inequality for the upper confidence bound from concentration analysis holds for actions in all rounds: $\\forall a$, \n",
    "\n",
    "\\begin{align*}\n",
    "|\\hat{\\mu}_a - \\mu_a| \\le \\epsilon \\\\\n",
    "\\mu_a - \\epsilon \\le \\hat{\\mu}_a \\le \\mu_a + \\epsilon\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67385a0f",
   "metadata": {},
   "source": [
    "where $\\epsilon = \\sqrt{\\frac{1}{2T_a(t)} \\ln \\frac{1}{\\delta}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ae0233",
   "metadata": {},
   "source": [
    "Then, we can apply the so-called UCB trick,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075d9fd",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mu_a + \\epsilon\n",
    "&\\ge \\hat{\\mu}_a \\\\\n",
    "\\mu_a + 2 \\epsilon \n",
    "&\\ge \\hat{\\mu}_a + \\epsilon \\\\\n",
    "&\\ge \\hat{\\mu}^* + \\epsilon^* \\\\\n",
    "&\\ge \\mu^* \\\\\n",
    "\\mu^* - \\mu_a \n",
    "&\\le 2\\epsilon \\\\\n",
    "\\Delta_a\n",
    "&\\le 2 \\sqrt{\\frac{1}{2T_a(t)} \\ln \\frac{1}{\\delta}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b44ef",
   "metadata": {},
   "source": [
    "Note, $\\mu^*$ and $\\hat{\\mu}^*$ may also have been written as $\\mu_{a^*}$ and $\\hat{\\mu}_{a^*}$, respectively, i.e. the (estimated) mean reward of the best action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa099680",
   "metadata": {},
   "source": [
    "Rearrange 6th inequality, we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de9513",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "T_a(t) \\le \\frac{2 \\ln (1/\\delta)}{\\Delta_a^2}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80275ee",
   "metadata": {},
   "source": [
    "which is just different from the corresponding Gaussian-bandit result by a factor of 4. $T_a(t) \\le \\frac{8 \\ln (1/\\delta)}{\\Delta_a^2}$ in the Gaussian case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0a97c",
   "metadata": {},
   "source": [
    "To use it in the decomposed regret, we need to obtain a bound for the expectation of $T_a(t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d1c61",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}[T_a(t)] \n",
    "&= \\mathbb{E}[T_a(t) | E] \\mathbb{P}(E) + \\mathbb{E}[T_a(t) | E^c] \\mathbb{P}[E^c] \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1262709",
   "metadata": {},
   "source": [
    "where we can bound each component as below,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5632951",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbb{E}[T_a(t) | E]\n",
    "&\\le \\frac{2 \\ln (1/\\delta)}{\\Delta_a^2} \\\\\n",
    "\\mathbb{P}(E) \n",
    "&\\le 1 \\\\\n",
    "\\mathbb{E}[T_a(t)|E^c] \n",
    "&\\le t \\\\\n",
    "\\mathbb{P}(E^c)\n",
    "&\\le 2 t \\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab5445",
   "metadata": {},
   "source": [
    "* 1st inequality is directly from result of UCB trick.\n",
    "* 2nd inequality holds for all probabilities.\n",
    "* 3rd inequality is because action $a$ can at most be played $t$ times after round $t$.\n",
    "* 4th inequality is based on union bound. Because $\\mathbb{P}(|\\hat{\\mu}_a - \\mu_a| \\ge \\epsilon) \\le 2\\delta$ per round, so $\\mathbb{P}(E^c) = \\mathbb{P}\\left( \\forall i \\le t; \\left|\\hat{\\mu}_{a, i} - \\mu_a \\right| \\le \\epsilon_{i,a} \\right) \\le 2t\\delta $ by union bound."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400ecc6",
   "metadata": {},
   "source": [
    "Therefore,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474c6fd",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbb{E}[T_a(t)] \n",
    "&\\le \\frac{2 \\ln (1/\\delta)}{\\Delta_a^2} \\cdot 1 + t \\cdot 2 t \\delta \\\\\n",
    "&= \\frac{2 \\ln (1/\\delta)}{\\Delta_a^2} + 2t^2 \\delta \\\\\n",
    "&\\le \\frac{4 \\ln t}{\\Delta_a^2} + 2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dea46",
   "metadata": {},
   "source": [
    "Note, in the 3rd inequality, we chose $\\delta = \\frac{1}{t^2}$, <span style=\"color:red\">but it's unclear yet how to justify this selection, and how far is $\\frac{4 \\ln n}{\\Delta_a^2} + 2$ from the true minimum of the RHS, which would've been minimized by $\\delta = \\frac{1}{t^2 \\Delta_a^2}$, but $\\Delta_a$ is unknown and can't be used for selecting $\\delta$. It'd be interesting to understand how the difference ($Delta$) changes as a function of $t$ and $\\Delta_a$, draft: $\\Delta = \\frac{4\\ln (t\\Delta_a) + 1 }{\\Delta_a^2} - \\frac{4 \\ln t}{\\Delta_a^2} - 2$.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d84f7e",
   "metadata": {},
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbb1f2",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "R_t \n",
    "&= \\sum_{a \\in \\mathcal{A} } \\Delta_a \\mathbb{E}[T_a(t)] \\\\\n",
    "&\\le \\sum_{a \\in \\mathcal{A} } \\frac{4 \\ln t}{\\Delta_a} + 2\\Delta_a\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac71eaa",
   "metadata": {},
   "source": [
    "The RHS can be quite big if $\\Delta_a$ is small, so we consider the actions that have a suboptimality gap above and below a cutoff $\\Delta$ separately,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b99d749",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "R_t\n",
    "&= \\sum_{a \\in \\mathcal{A}: \\Delta_a \\le \\Delta} \\Delta_a \\mathbb{E}[T_a(t)] + \\sum_{a \\in \\mathcal{A}: \\Delta_a > \\Delta} \\Delta_a \\mathbb{E}[T_a(t)] \\\\\n",
    "&\\le t \\Delta +  \\sum_{a \\in \\mathcal{A}, \\Delta_a > \\Delta } \\frac{4 \\ln t}{\\Delta_a} + 2\\Delta_a \\\\\n",
    "&\\le t \\Delta + \\frac{4k \\ln t}{\\Delta} + 2k \\max_{a} \\Delta_a\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee112db",
   "metadata": {},
   "source": [
    "Note,\n",
    "\n",
    "* in 3rd equality, $k$ is the number of actions, i.e. $k = |\\mathcal{A}|$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d34853",
   "metadata": {},
   "source": [
    "Minimizing the RHS of the third equality wrt. $\\Delta$ leads to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9b6d0",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\tilde{\\Delta} = \\arg \\min_{\\Delta} t \\Delta t  + \\frac{4k \\ln t}{\\Delta} = 2 \\sqrt{\\frac{k \\ln t}{t}} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba22d6c",
   "metadata": {},
   "source": [
    "so "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b3539",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "R_t \n",
    "&\\le 2 \\sqrt{t k \\ln t} + 2 \\sqrt{t k \\ln t} + C \\\\\n",
    "&\\le O(\\sqrt{tk\\ln t})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2527a",
   "metadata": {},
   "source": [
    "This approach is called minimax bound perhaps because it's minimizing the maximum of the RHS (NOT totally sure yet)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
