{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e4a043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf381b",
   "metadata": {},
   "source": [
    "# Definition of subgaussianity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587a61a",
   "metadata": {},
   "source": [
    "For a Gaussian random variable $X \\sim \\mathcal{N}(0, \\sigma^2)$, its moment-generating function (MGF) is "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a836730d",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "M_X(t) = \\mathbb{E}\\left[e^{t X} \\right] = \\exp \\left( \\frac{t^2 \\sigma^2}{2} \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f8b24",
   "metadata": {},
   "source": [
    "See Appendix for a derivation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872ac95",
   "metadata": {},
   "source": [
    "Then we call a random variable $Y$ $\\sigma$-subgaussian if for all $t \\in \\mathbb{R}$, \n",
    "\n",
    "\\begin{align*}\n",
    "M_Y(t) = \\mathbb{E}\\left[e^{t Y} \\right] \\le \\exp \\left( \\frac{t^2 \\sigma^2}{2} \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ee27b",
   "metadata": {},
   "source": [
    "In other words, $Y$ is subgaussian in the sense that its MGF is no bigger than that of $\\mathcal{N}(0, \\sigma^2)$. Note, $\\mathcal{N}(0, \\sigma^2)$ is $\\sigma$-subguassian itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763fc816",
   "metadata": {},
   "source": [
    "# Concentration analysis for a single $\\sigma$-gaussian r.v."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839f7da",
   "metadata": {},
   "source": [
    "First, let's bound the tails for a $\\sigma$-subgaussian r.v. $X$ using Cramér-Chernoff method. For any $\\epsilon > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4cc49",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbb{P}(X \\ge \\epsilon)\n",
    "&= \\mathbb{P}(\\lambda X \\ge \\lambda \\epsilon) \\\\\n",
    "&= \\mathbb{P}(e^{\\lambda X} \\ge e^{\\lambda \\epsilon}) \\\\\n",
    "&\\le \\frac{\\mathbb{E}[e^{\\lambda X}]}{e^{\\lambda \\epsilon}} \\\\\n",
    "&\\le \\exp\\left(\\frac{\\lambda^2 \\sigma^2}{2} - \\lambda \\epsilon \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24763435",
   "metadata": {},
   "source": [
    "Note,\n",
    "\n",
    "* $\\lambda > 0$.\n",
    "* 3rd inequality is from the application of Markov's inequality.\n",
    "* 4th inequality holds because $X$ is $\\sigma$-subgaussian and $ \\mathbb{E}\\left[e^{\\lambda X} \\right] \\le \\exp \\left( \\frac{\\lambda^2 \\sigma^2}{2} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8afc8",
   "metadata": {},
   "source": [
    "The RHS of the 4th inequality is minimized by $\\lambda = \\epsilon / \\sigma^2$, so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41e04c",
   "metadata": {},
   "source": [
    "\\begin{align*} \n",
    "\\mathbb{P}(X \\ge \\epsilon) \n",
    "&\\le \\exp\\left(\\frac{\\epsilon^2}{\\sigma^4} \\frac{\\sigma^2}{2} - \\frac{\\epsilon}{\\sigma^2} \\epsilon \\right) \\\\\n",
    "&= \\exp \\left( -\\frac{\\epsilon^2}{2 \\sigma^2 } \\right )\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fe29a",
   "metadata": {},
   "source": [
    "Abound for the left tail can be obtain in a similar way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fab72",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbb{P}(X \\le - \\epsilon)\n",
    "&= \\mathbb{P}(- X \\ge \\epsilon) \\\\\n",
    "&= \\mathbb{P}(- \\lambda X \\ge  \\lambda \\epsilon) \\\\\n",
    "&= \\mathbb{P}(e^{- \\lambda X} \\ge e^{\\lambda \\epsilon}) \\\\\n",
    "&\\le \\frac{\\mathbb{E}[e^{- \\lambda X}]}{e^{\\lambda \\epsilon}} \\\\\n",
    "&\\le \\exp \\left(\\frac{\\lambda^2 \\sigma^2}{2} - \\lambda \\epsilon \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d675e641",
   "metadata": {},
   "source": [
    "so $\\mathbb{P}(X \\le - \\epsilon)$ has the same bound as $\\mathbb{P}(X \\ge - \\epsilon)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610cd38",
   "metadata": {},
   "source": [
    "Therefore, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a666c",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(X \\ge \\epsilon) &\\le \\exp \\left( -\\frac{\\epsilon^2}{2 \\sigma^2 } \\right ) \\\\\n",
    "\\mathbb{P}(X \\le - \\epsilon) &\\le \\exp \\left( -\\frac{\\epsilon^2}{2 \\sigma^2 } \\right )\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c1e70e",
   "metadata": {},
   "source": [
    "If we set $\\delta = \\exp \\left( -\\frac{\\epsilon^2}{2 \\sigma^2 } \\right )$, then $\\epsilon = \\sqrt{2 \\sigma^2 \\ln 1/\\delta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3808f3",
   "metadata": {},
   "source": [
    "Using union bound, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b8759",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(X \\ge \\epsilon) &\\le \\delta \\\\\n",
    "\\mathbb{P}(X \\le - \\epsilon) &\\le \\delta  \\\\\n",
    "\\mathbb{P}(|X| \\ge \\epsilon) \n",
    "&= \\mathbb{P} \\left(|X| \\ge \\sqrt{2 \\sigma^2 \\ln 1/\\delta} \\right) \\\\\n",
    "&\\ge 2 \\delta\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de36ed80",
   "metadata": {},
   "source": [
    "# Concentration analysis for mean of multiple $\\sigma$-gaussian r.v.s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ee5c2",
   "metadata": {},
   "source": [
    "Using the Cramér-Chernoff method in the same way as in `Prove-regret-bounds-for-UCB-for-stochastic-Gaussian-bandits-with-variance-1.ipynb` and `Prove-regret-bounds-UCB-with-stochastic-Bernoulli-bandits.ipynb`, we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927a76f",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(\\hat{\\mu} \\ge \\mu + \\epsilon)\n",
    "&le \\frac{\\prod_{t=1}^T \\mathbb{E}\\left[ e^{\\lambda \\left( X_t - \\mu \\right )} \\right ]}{e^{\\lambda T \\epsilon}} \\\\\n",
    "&\\le \\frac{\\mathbb{E}\\left[ \\exp \\left( \\frac{\\lambda^2 \\sigma^2 }{2} \\right ) \\right ]}{\\exp \\left(e^{\\lambda T \\epsilon} \\right )} \\\\\n",
    "&=\\exp \\left( \\frac{T \\lambda^2\\sigma^2}{2} - \\lambda T \\epsilon \\right )\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc096272",
   "metadata": {},
   "source": [
    "Denote the RHS as $f(\\lambda) = \\exp \\left( \\frac{T \\lambda^2\\sigma^2}{2} - \\lambda T \\epsilon \\right )$, then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe206d9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min_{\\lambda > 0} f = \\exp \\left( - \\frac{T \\epsilon^2}{2 \\sigma^2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f95c18",
   "metadata": {},
   "source": [
    "where $\\arg \\min_{\\lambda > 0} f = \\epsilon / \\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a30f2",
   "metadata": {},
   "source": [
    "Therefore,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273b22f",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}(\\hat{\\mu} \\ge \\mu + \\epsilon)\n",
    "\\le \\exp \\left( - \\frac{T \\epsilon^2}{2 \\sigma^2} \\right)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfba01",
   "metadata": {},
   "source": [
    "Set RHS as $\\delta = \\exp \\left( - \\frac{T \\epsilon^2}{2 \\sigma^2} \\right)$, then $\\epsilon = \\sqrt{\\frac{2 \\sigma^2 \\ln 1 /\\delta}{T}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66434d0d",
   "metadata": {},
   "source": [
    "So "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ad30c",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P} \\left(\\hat{\\mu} \\ge \\mu + \\sqrt{\\frac{2 \\sigma^2 \\ln 1 /\\delta}{T}} \\right)\n",
    "\\le \\delta\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af60236",
   "metadata": {},
   "source": [
    "Following the same steps analyzing $\\mathbb{P}(\\hat{\\mu} \\le \\mu - \\epsilon) = \\mathbb{P}(\\mu -\\hat{\\mu} \\ge \\epsilon)$, and we can get the bound for the left tail,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eadd08",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P} \\left(\\hat{\\mu} \\ge \\mu - \\sqrt{\\frac{2 \\sigma^2 \\ln 1 /\\delta}{T}} \\right)\n",
    "\\le \\delta\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de4999",
   "metadata": {},
   "source": [
    "Note the two bounds are almost the same to those for the $\\mathcal{N}(0, 1)$ just with an extra $\\sigma^2$. They'd be identical for $\\mathcal{N}(\\mu, \\sigma^2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb6552",
   "metadata": {},
   "source": [
    "# Properties of $\\sigma$-subgaussian variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47f1fa",
   "metadata": {},
   "source": [
    "* $\\mathbb{E}[X] = 0$, $\\mathbb{V}[X] \\le \\sigma^2$.\n",
    "* $cX$ is $|c|\\sigma$-subgaussian for all $c \\in \\mathbb{R}$.\n",
    "* $X_1 + X_2$ is $\\sqrt{\\sigma_1^2 + \\sigma_2^2}$-subgaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e909dcc",
   "metadata": {},
   "source": [
    "These are also in Exercise 5.7 of the banditalgs book. See Appendix for proofs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99270593",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8ca95",
   "metadata": {},
   "source": [
    "### Derive MGF for $\\mathcal{N}(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3978c0",
   "metadata": {},
   "source": [
    "\\begin{align} \n",
    "\\mathbb{E}[e^{\\lambda X}]\n",
    "&= \\int \\exp(\\lambda x) \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left( -\\frac{x^2}{2\\sigma^2}\\right ) dx \\\\\n",
    "&= \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\int \\exp\\left[ -\\frac{1}{2\\sigma^2} \\left(x^2 - 2\\sigma^2 \\lambda x \\right ) \\right ] dx \\\\\n",
    "&= \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\int \\exp\\left[ -\\frac{1}{2\\sigma^2} \\left( \\left(x - \\sigma^2 \\lambda \\right )^2 - \\sigma^4 \\lambda^2 \\right ) \\right ] dx \\\\\n",
    "&= \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(\\frac{\\lambda^2 \\sigma^2}{2} \\right) \\int \\exp\\left[ -\\frac{1}{2\\sigma^2} \\left(x - \\sigma^2 \\lambda \\right )^2  \\right ] dx \\\\\n",
    "&= \\exp\\left(\\frac{\\lambda^2 \\sigma^2}{2} \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ee83e",
   "metadata": {},
   "source": [
    "Note, in 5th equality, $\\int \\exp\\left[ -\\frac{1}{2\\sigma^2} \\left(x - \\sigma^2 \\lambda \\right )^2  \\right ] dx = \\sqrt{2\\pi\\sigma^2}$ because it's the unnormalized distribution of $\\mathcal{N}(\\sigma^2 \\lambda, \\sigma^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5eb826",
   "metadata": {},
   "source": [
    "A derivation of MGF for the more general $\\mathcal{N}(\\mu, \\sigma^2)$ is available [here](https://zyxue.github.io/2021/08/29/gaussian-distributions.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69a00b",
   "metadata": {},
   "source": [
    "### Properties of $\\sigma$-subgaussian r.v."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e15f3",
   "metadata": {},
   "source": [
    "The proofs is based on refs from \n",
    "\n",
    "* http://lear.inrialpes.fr/people/harchaoui/teaching/2013-2014/ensl/m2/lecture6.pdf (main one)\n",
    "* https://www.stat.cmu.edu/~arinaldo/Teaching/36710/F18/Scribed_Lectures/Sep5.pdf\n",
    "* https://ocw.mit.edu/courses/18-s997-high-dimensional-statistics-spring-2015/a69e2f53bb2eeb9464520f3027fc61e6_MIT18_S997S15_Chapter1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bb22ae",
   "metadata": {},
   "source": [
    "#### Show $\\mathbb{E}[X] = 0$, $\\mathbb{V}[X] \\le \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b6af5",
   "metadata": {},
   "source": [
    "Expand both sides of $\\mathbb{E}\\left[e^{t X} \\right] \\le \\exp \\left( \\frac{t^2 \\sigma^2}{2} \\right)$ with Taylor series,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f09e8",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbb{E}\\left[1 + tX + \\frac{(tx)^2}{2} + \\cdots \\right ] \n",
    "\\le 1 + \\frac{t^2 \\sigma^2}{2} + \\frac{(t^2 \\sigma^2 / 2)^2}{2} + \\cdots\n",
    "\\\\\n",
    "t\\mathbb{E}[X] + \\frac{t^2}{2}\\mathbb{E}[X^2] \\le \\frac{t^2 \\sigma^2}{2} + g(t) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ebab52",
   "metadata": {},
   "source": [
    "where $g(t)$ is a sum of all terms with a factor $t^k$ where $k \\ge 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03eedd9",
   "metadata": {},
   "source": [
    "To understand $\\mathbb{E}[X]$, rearrange 2nd inequality,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d310f84",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "t\\mathbb{E}[X] \\le \\frac{t^2 \\sigma^2}{2} - \\frac{t^2}{2}\\mathbb{E}[X^2]  + g(t) \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6aac35",
   "metadata": {},
   "source": [
    "When $t > 0$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2392056",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}[X] \n",
    "&\\le \\frac{t \\sigma^2}{2} - \\frac{t}{2}\\mathbb{E}[X^2]  + \\frac{g(t)}{t} \\\\\n",
    "\\lim_{t \\rightarrow 0_+} \\mathbb{E}[X]\n",
    "&\\le 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c954767",
   "metadata": {},
   "source": [
    "Note $\\lim_{t \\rightarrow 0} \\frac{g(t)}{t} = 0$ because all terms of $\\frac{g(t)}{t}$ contains a factor $t^k$ where $k \\ge 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ded5f",
   "metadata": {},
   "source": [
    "When $t < 0$, similarly, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863871e3",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}[X] \n",
    "&\\ge \\frac{t \\sigma^2}{2} - \\frac{t}{2}\\mathbb{E}[X^2]  + \\frac{g(t)}{t} \\\\\n",
    "\\lim_{t \\rightarrow 0_-} \\mathbb{E}[X]\n",
    "&\\ge 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1fe603",
   "metadata": {},
   "source": [
    "When $t = 0$, the inequality $\\mathbb{E}\\left[e^{t X} \\right] \\le \\exp \\left( \\frac{t^2 \\sigma^2}{2} \\right)$ obviously also holds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ab081",
   "metadata": {},
   "source": [
    "Therefore, to have $\\mathbb{E}\\left[e^{t X} \\right] \\le \\exp \\left( \\frac{t^2 \\sigma^2}{2} \\right)$ hold for all $t \\in \\mathbb{R}$, $\\mathbb{E}[X] = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f070690",
   "metadata": {},
   "source": [
    "To understand $\\mathbb{E}[X^2]$, rearrange the Taylor expanded inequality plugging in $\\mathbb{E}[X] = 0$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27be998",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{t^2}{2}\\mathbb{E}[X^2] \n",
    "&\\le \\frac{t^2 \\sigma^2}{2} + g(t) \\\\\n",
    "\\mathbb{E}[X^2] \n",
    "&\\le \\sigma^2 + \\frac{2 g(t)}{t^2} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40698d4c",
   "metadata": {},
   "source": [
    "$\\lim_{t \\rightarrow 0} \\sigma^2 + \\frac{2 g(t)}{t^2} = \\sigma^2 $ because all terms of $g(t)$ have an order higher than 3 in $t$, so $\\sigma^2$ is an upper bound for $\\mathbb{E}[X^2]$, i.e. $\\mathbb{V}[X] = \\mathbb{E}[X^2] \\le \\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938d2ff",
   "metadata": {},
   "source": [
    "QED."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450dbb7",
   "metadata": {},
   "source": [
    "#### Show $cX$ is $|c|\\sigma$-subgaussian for all $c \\in R$ if $X$ is $\\sigma$-subgaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d37707",
   "metadata": {},
   "source": [
    "By definition of $X$ being $\\sigma$-subgaussian for all $t \\in \\mathbb{R}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f19e7b",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[e^{t X} \\right] \n",
    "&\\le \\exp \\left( \\frac{t^2 \\sigma^2}{2} \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d85f7a",
   "metadata": {},
   "source": [
    "so it also holds for $h = ct \\in \\mathbb{R}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187bee05",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[e^{h X} \\right] \n",
    "&\\le \\exp \\left( \\frac{h^2 \\sigma^2}{2} \\right) \\\\\n",
    "\\mathbb{E}\\left[e^{ct X} \\right] \n",
    "&\\le \\exp \\left( \\frac{(ct)^2 \\sigma^2}{2} \\right) \\\\\n",
    "\\mathbb{E}\\left[e^{t (cX)} \\right] \n",
    "&\\le \\exp \\left( \\frac{t^2 (c\\sigma)^2}{2} \\right) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a941c4",
   "metadata": {},
   "source": [
    "Therefore, $cX$ is $|c|\\sigma$-subgaussian. QED."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a514c",
   "metadata": {},
   "source": [
    "#### Show $X_1 + X_2$ is $\\sqrt{\\sigma_1^2 + \\sigma_2^2}$-subgaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee250a3",
   "metadata": {},
   "source": [
    "By definition, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe14517",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[e^{t X_1} \\right] \n",
    "&\\le \\exp \\left( \\frac{t^2 \\sigma_1^2}{2} \\right) \\\\\n",
    "\\mathbb{E}\\left[e^{t X_2} \\right] \n",
    "&\\le \\exp \\left( \\frac{t^2 \\sigma_2^2}{2} \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f17ecd",
   "metadata": {},
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ccb63",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[e^{t X_1} \\right] + \\mathbb{E}\\left[e^{t X_2} \\right]\n",
    "&\\le \\exp \\left( \\frac{t^2 \\sigma_1^2}{2} \\right) + \\exp \\left( \\frac{t^2 \\sigma_2^2}{2} \\right) \\\\\n",
    "\\mathbb{E}\\left[e^{t (X_1 + X_2) } \\right]\n",
    "&\\le \\exp \\left( \\frac{t^2 \\left( \\sigma_1^2 + \\sigma_2^2 \\right )}{2} \\right) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a45319",
   "metadata": {},
   "source": [
    "Therefore, $X_1 + X_2$ is $\\sqrt{\\sigma_1^2 + \\sigma_2^2}$-subgaussian, QED."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
